{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUÍA DE PANDAS\n",
    "###### 5/03/2021\n",
    "\n",
    "\n",
    "Hay una guia genial de pandas en este enlace https://towardsdatascience.com/40-examples-to-master-pandas-c69d058f434e\n",
    "\n",
    "Otra aquí : https://joserzapata.github.io/courses/python-ciencia-datos/pandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv en la misma carpeta del jupiter notebook\n",
    "df = pd.read_csv(\"dataframe.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# si el dataframe está una carpeta por debajo de donde abres el notebook\n",
    "df = pd.read_csv(\"nombrecarpeta/dataframe.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Añadiendo el nombre de las columnas y el tipo de datos\n",
    "df = pd.read_csv(\"data/laliga.csv\",\n",
    "                usecols = ['Unnamed: 0', 'division', 'localTeam'],\n",
    "                dtype = {'Unnamed: 0': np.object,\n",
    "                         'division': np.int64,\n",
    "                         'localTeam': np.object})\n",
    "\n",
    "#esto es para guardar el dataframe en un archivo csv en el ordenador.\n",
    "\n",
    "df.to_csv(\"data/laligaWrite.csv\", sep=\";\", index = False)\n",
    "#index = False es para que no nos guarde el indice como unnamed en el csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar dataframes a partir de datos en Excel. Le especifico que quiero los datos de un COLUMNA ESPECÍFICA como índice.\n",
    "\n",
    "df = pd.read_excel(\"data/laliga.xlsx\", index_col = \"Unnamed: 0\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"nombre excel\", \n",
    "    sheet_name= \"nombre pestañas\",\n",
    "    header = 5, \n",
    "    nrows = 83,\n",
    "    names = ['Tax Jurisdiction',\n",
    " 'Third-Party Revenues',\n",
    " 'Related-Party Revenues',\n",
    " 'Total Revenues',\n",
    " 'Profit Before Tax',\n",
    " 'Tax Paid',\n",
    " 'Tax Accrued',\n",
    " 'Stated Capital',\n",
    " 'Accumulated Earnings',\n",
    " 'Tangible Assets',\n",
    " 'Number of employees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#esto es para guardar el dataframe en un archivo csv en el ordenador.\n",
    "\n",
    "df.to_csv(\"data/laligaWrite.csv\", sep=\";\", index = False)\n",
    "#index = False es para que no nos guarde el indice como unnamed en el csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),\n",
    "                  index=['mouse', 'rabbit'],\n",
    "                  columns=['one', 'two', 'three'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atributos del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size #devuelve el número de valores del dataframe en un entero de numpy:numpy.int32\n",
    "df.shape #devuelve una tupla de dos elementos:(nº de filas, nº de columnas). Por ej.(1272, 161)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .columns\n",
    "\n",
    "df.columns #devuelve un objeto Index que contiene los títulos de todas las columnas. \n",
    "print(type(df.columns))#<class 'pandas.core.indexes.base.Index'>\n",
    "\n",
    "for item in df.columns:#es un iterable.Cada item es un titulo de columna i.e un string. \n",
    "    print(item)\n",
    "type(item)#str.\n",
    "\n",
    "df.colums.tolist() #Te devuelve una lista de python que contiene los nombres de las columnas.\n",
    "\n",
    "\n",
    "df.columns.values#Acceder a los nombres de las columnas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asignar un index nuevo al dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = list([]) #con elementos concretos \n",
    "\n",
    "df.reset_index()#mete el antiguo indice en una columna y renumera el índice del dataframe con un rango numérico\n",
    "                #del 0 al que sea.\n",
    "    \n",
    "df.set_index(\"nombre_columna\") #esto es para establecer una columna como índice del df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Médodos para obtener información sobre el dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()#num filas y columnas, tipo de valores, nulos.\n",
    "df.describe()#información estadística.\n",
    "df.head()\n",
    "df.tail()\n",
    "df.sample()#Return a random sample of items from an axis of object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acceder a los elementos del dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar una columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nombre_columna\"] #devuelve un objeto Series de pandas que contiene los valores de la columa y un índice.\n",
    "\n",
    "type(df[\"nombre_columna\"]) #pandas.core.series.Series. \n",
    "\n",
    "df[\"nombre_columna\"].unique() #devuelve un array unidisional de numpy que contiene los valores únicos de la \n",
    "                                #columna.Pueden ser numéricos o string.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar varias columnas a la vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para seleccionar varias columnas utilizamos doble corchete: el primero porque estamos seleccionando\n",
    "#y el segundo porque lo que estamos seleccionando es una lista (de columnas) y las listas van entre corchetes.\n",
    "\n",
    "df2[[\"nombre_columna_1\",\"nombre_columna_2\",\"nombre_columna_3\"]]\n",
    "#devuelve un objeto dataframe que contiene las columnas seleccionadas\n",
    "\n",
    "type(df2[[\"nombre_columna_1\",\"nombre_columna_2\",\"nombre_columna_3\"]]) #pandas.core.frame.DataFrame\n",
    "\n",
    "#Utilizando índice implícito (iloc.())\n",
    "\n",
    "df.iloc[:,2:] #seleccionamos todas las filas y desde la segunda columna en adelante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionar filas : slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indice implícito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando índice implícito (iloc.()). Se busca por el índice implícito de la fila, de 0 a n.\n",
    "\n",
    "df.iloc[0] #Me devuelve un series que contiene todos los valores de la fila con índice implícito 0.\n",
    "df.iloc[:0,:] #Me devuelve un dataframe que contiene todos los valores de la fila con índice implícito 0.\n",
    "df.iloc[:5] #Me devuelve un dataframe con los valores de las filas con índice implícito 0 a la 4.\n",
    "\n",
    "#### Seleccionar valores concretos\n",
    "\n",
    "df.iloc[0,2] #selecciona el valor en por indice implicito de fila, columna.\n",
    "df.iloc[0].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indice explícito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando método explícito, es decir, las etiquetas del índice.Te permite localizar las etiquetas\n",
    "#del índice haciendo un slicing o usando un array o Series booleano. El segundo término (después de la coma) \n",
    "#indica la columna que quieres visualizar.\n",
    "\n",
    "df.loc[0]  #Me devuelve un series que contiene todos los valores de la fila con índice explícito 0, es decir, cuyo índice se llama \"0\", sea la que sea su posición en el implícito.\n",
    "df.loc[:0,:]  #Me devuelve un dataframe que contiene todos los valores de la fila con índice explícito 0.\n",
    "df.loc[:5] #Me devuelve un dataframe con los valores de las filas con índice explícito 0 a la 5. OJO: Incluye la fila con índice 5.\n",
    "df.loc[['fila', 'col']]# Devuelve el valor en esa fila y col\n",
    "df.loc[['fila 2': 'fila 8', 'col']]#Devuelve los valores en esas filas y col\n",
    "df.loc[[False, True, False],\"col\"] #Devuelve los valores en las filas filtradas por el booleano y col\n",
    "df.loc[[boolean Series],\"col\"] #Devuelve los valores en las filas filtradas por el booleano y col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ejemplo: df con indice usuario_001, usuario_002, usuario _0003, etc.\n",
    "Para extraer los valores de la fila correspondiente al usuario_002, puedo hacerlo con los dos métodos: \n",
    "\n",
    "df.iloc[1]\n",
    "df.loc[usuario_002]\n",
    "\n",
    "\"\"\"  \n",
    "\n",
    "#### Seleccionar valores concretos\n",
    "\n",
    "df.iloc[0,2] #selecciona el valor en por indice implicito de fila, columna.\n",
    "\n",
    "df.iloc[0].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recorrer filas / columnas de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over DataFrame rows as (index, Series) pairs.\n",
    "\n",
    "df.iterrows()\n",
    "\n",
    "# Recorrer las columnas con un contador usando enumerate (python built-in)\n",
    "\n",
    "for i, element in enumerate(df.columns):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reordenar filas / columnas de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reordenar columnas\n",
    "\n",
    "df.reindex(columns=['col1', 'col2', \"col3\"])\n",
    "df.reindex(['col1', 'col2', \"col3\"], axis=\"columns\")\n",
    "\n",
    "#Reordenar filas\n",
    "\n",
    "df.reindex(['fila0', \"fila2\" 'fila2', \"fila3\"])\n",
    "\n",
    "#si al hacer el reindex no incluyo una las filas o columnas, la elimina del dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localizar las columnas categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el método .select_dtypes():\n",
    "\n",
    "df.select_dtypes(['object']) # Obtenemos un df con todas las columnas categóricas (o Series si sólo hay una)\n",
    "\n",
    "#Podemos extraer los nombres de las columnas categóricas con un bucle o comprehension usando el método .dtpe():\n",
    "\n",
    "#Bucle:\n",
    "\n",
    "cat = {}\n",
    "for i,col in enumerate(df_total.columns):\n",
    "    if df[col].dtype == \"object\":\n",
    "        cat[i] = col\n",
    "        \n",
    "cat = []\n",
    "for i,col in enumerate(df_total.columns):\n",
    "    if df[col].dtype == \"object\":\n",
    "        cat.append(col)\n",
    "        \n",
    "#Comprehension:\n",
    "\n",
    "[col for col in df_total.columns if df_total[col].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpiar el dataframe\n",
    "\n",
    "##### Generalmente, para que el dataframe original se vea modificado, tendremos que sobreescribirlo o utilizar el inplace =True. \n",
    "\n",
    "##### Cuando tenemos que hacer muchos cambios al dataframe original, lo normal es cargarlo como raw data y montar un dataframe que será una copia del raw data para trabajar sobre el e ir sobreescribiéndolo.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#redondear los valores numéricos del dataframe\n",
    "\n",
    "round(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Valores NULOS\n",
    "\n",
    "#Para averiguar si el df tiene valores nulos\n",
    "\n",
    "vod_2019.isnull().any() #te devuelve un true o false por variable\n",
    "\n",
    "vod_2019.isnull().any().any() #te devuelve un true o false para todo el df\n",
    "np.any(df.isnull())#Otra forma de que devuelva un true o false para todo el df\n",
    "\n",
    "#Contar valores nulos\n",
    "\n",
    "#Por variable\n",
    "df.isnull().sum()\n",
    "\n",
    "#Por instancia\n",
    "df.isnull().sum(axis=1)\n",
    "\n",
    "#Eliminar los valores nulos:\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "# Reemplazar missings \n",
    "\n",
    "df.fillna(0,inplace=True)\n",
    "df.fillna(\"missing\",inplace=True)\n",
    "\n",
    "#Reemplazar missings por media u otros estadísticos\n",
    "\n",
    "df[col] = df[col].fillna(df[col].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Infinitos: reemplazarlos por Nan y eliminar los registros\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True).dropna(how=\"all\",inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renombrar columnas (rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#le damos una lista con los nuevos nombres de TODAS las columnas.\n",
    "planets.columns = ['método', 'número', 'periodo_orbital', 'masa', 'distancia', 'año']\n",
    "\n",
    "\n",
    "#Cambiamos el nombre de alguna/s columna/s\n",
    "df.rename(columns={\"nombre_antiguo\" : \"nombre_nuevo\", \"nombre_antiguo\" : \"nombre_nuevo\"}, inplace=True)\n",
    "df = df.rename(columns={\"nombre_antiguo\" : \"nombre_nuevo\", \"nombre_antiguo\" : \"nombre_nuevo\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intercambiar filas y columnas (transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.transpose()\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordenar (sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordenar los valores de una columna: \n",
    "\n",
    "df[\"nombre_columna\"].sort_values()\n",
    "df[\"nombre_columna\"].sort_values(ascending = False)\n",
    "\n",
    "#Ordenar los valores del dataframe en función de una columna. \n",
    "df.sort_values(\"nombre_columna\")\n",
    "\n",
    "#Ordenar los valores del dataframe en función de dos columnas.\n",
    "#Primero ordena las instancias en función de una columna \n",
    "#y luego ordena las instancias dentro de cada nivel de la primera columna por la segunda columna)\n",
    "\n",
    "df.sort_values([\"nombre_columna1\",\"nombre_columna2\", ascending = [False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insertar columnas (insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar una nueva columna en la posición donde te interesa colocarla. \n",
    "\n",
    "#Por ejemplo, código para crear una nueva columna que resulta de la división de la columna 3 entre la 4, y crearla en la posición 1. \n",
    "\n",
    "df.insert(1,\"nombre nueva col\", df[col3] / df[col4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Añadir filas al dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El método append de Pandas está deprecated, hay que usar concat.\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame.from_records([diccionario])])\n",
    "\n",
    "# El diccionario contentrá el titulo de la columna y el valor para la nueva fila a añadir. Por ejemplo:\n",
    "# diccionario = {\"col1\" : \"nuevo valor\",\"col2\" : \"nuevo valor\",\"col3\" : \"nuevo valor\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otra forma con .loc()\n",
    "\n",
    "new_row = [\"col1_value\", \"col2_value\", \"col3_value\"]\n",
    "\n",
    "df.loc[-1] = new_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar columnas y filas de un dataframe (drop y del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar una columna (drop)\n",
    "\n",
    "df.drop(columns=[\"nombre_columna\"])\n",
    "\n",
    "#Eliminar varias columnas\n",
    "\n",
    "df.drop(['col1', 'col2'], axis = \"columns\" , inplace=True)#axis acepta 0 o \"index\" y 1 o \"columns\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas (drop con axis = 0 o a index)\n",
    "\n",
    "\"\"\"\n",
    "Ejemplo: df con indice usuario_001, usuario_002, usuario _0003, etc.\n",
    "Quiero eliminar la fila correspondiente al indice \"usuario_002\"\n",
    "También se puede usar con el índice implícito.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df.drop(['usuario:002',\"usuario:003\"],axis = 0)\n",
    "\n",
    "df.drop('usuario:002',axis = \"index\")#explícito\n",
    "df.drop(0,axis = \"index\")\n",
    "\n",
    "#El valor de axis por default es 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otra forma de borrar columnas (método del)\n",
    "\n",
    "del df['col1'] # Esta funcion es INPLACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para detectarlos\n",
    "\n",
    "df.duplicated()\n",
    "\n",
    "#para eliminarlos y que el dataframe te renumere el índice:\n",
    "\n",
    "df.drop_duplicates(ignore_index = True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reemplazar valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al Series columna se le puede aplicar el médodo str.replace()\n",
    "\n",
    "df2[\"nombre_columna\"] = df2[\"nombre_columna\"].str.replace(\"$\", \"\")#Eliminar el signo de dolar\n",
    "\n",
    "df2[\"nombre_columna\"] = df2[\"nombre_columna\"].str.replace(\"$|,\", \"\")#Elimir el signo del dolar o la coma\n",
    "\n",
    "df2[\"nombre_columna\"] = df2[\"nombre_columna\"].str.replace(\",\", \".\")#Reemplazar la coma por un punto.\n",
    "\n",
    "#Si el replace lo queremos aplicar para varias columnas del dataframe tendremos que hacer un bucle for:\n",
    "\n",
    "for item in list(df.columns):#iteramos sobre una lista de python que contiene los nombres de las columnas\n",
    "    print(item)\n",
    "    try:\n",
    "        df[item] = df[item].str.replace(\"%\",\"\")#eliminamos el signo del porcentaje de todas las columnas\n",
    "    except:\n",
    "        continue#si la columna no tiene porcentaje no me des error, sigue adelante.\n",
    "        \n",
    "# Parece que también se puede hacer para todo el df, con replace.\n",
    "\n",
    "df_replaced = df.replace(%,0)\n",
    "\n",
    "# Reemplazar missings por ceros\n",
    "\n",
    "df = df.fillna(0,inplace=True)\n",
    "\n",
    "#Reemplazar missings por media u otros estadísticos\n",
    "\n",
    "df[col] = df[col].fillna(df[col].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazar valores en un dataframe sin que que salga el error \"A value is trying to be set on a copy of a slice from a DataFrame\"\n",
    "\n",
    "df.loc[mask, \"col\"] = 40\n",
    "\n",
    "# Al respecto, ver https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando el método replace, que se puede aplicar a todo el dataframe:\n",
    "\n",
    "df_replaced = df.replace(%,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando una el método applymap (máp + lambda)\n",
    "\n",
    "df.applymap(lambda x: len(str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir todos los valores del dataframe en strings\n",
    "\n",
    "df.applymap(str) \n",
    "\n",
    "df.astype(\"str\")\n",
    "\n",
    "#convertir todos los valores del dataframe en enteros. Ojo, que si hay columnas categóricas\n",
    "#dará error y tendremos que aplicar el astype sobre un slicing que deje fuera las categóricas.\n",
    "\n",
    "df.astype(\"int\")\n",
    "df.iloc[:,1:].astype(\"int\")\n",
    "\n",
    "#o bien: incluir el parámetro \"errors\"\n",
    "\n",
    "df.astype(\"int\",errors='ignore')\n",
    "\n",
    "#Convertir un series o lista o array en int:\n",
    "pd.to_numeric(lista, downcast='integer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generar una nueva columna en función de los valores de otra, con un apply.\n",
    "\n",
    "def funcion(x):\n",
    "\n",
    "    if x < 1:\n",
    "        x = \"a\"\n",
    "    \n",
    "    elif x > 1:\n",
    "        \n",
    "        x = \"b\"\n",
    "    \n",
    "    return x\n",
    "\n",
    "dif_aum[\"col_nueva\"] = dif_aum[\"col_referencia\"].apply(funcion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando apply con lambda\n",
    "\n",
    "df[\"salary_clean\"] = df[\"salary\"].apply(lambda x : x.replace('K','').replace('$',''))\n",
    "\n",
    "df['Excel'] = df['Job Description'].apply(lambda x : 1 if 'excel' in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GROUP BY\n",
    "\n",
    "#Agrupamos el dataframe por el contenido de la columna número 1.\n",
    "\n",
    "df2.groupby(\"columna_1\")#Esto no se puede imprimir, es un objeto tipo Groupby i.e pandas.core.groupby.generic.DataFrameGroupBy\n",
    "\n",
    "df2.groupby(\"columna_1\").sum()#esto devuelve un dataframe agrupado por el contenido de la columna 1, \n",
    "                                    #sumando sus valores. Devuelve un objeto tipo dataframe. \n",
    "df2.groupby(\"columna_1\").count()\n",
    "\n",
    "\n",
    "#Agrupamos el dataframe por el contenido de la columna 1 y despues por el de la columna 2.    \n",
    "\n",
    "df.groupby(\"nombre_col1\")[\"nombre_col2\"] #esto es un objeto tipo groupby al que podemos aplicar metodos\n",
    "\n",
    "df.groupby(\"nombre_col1\")[\"nombre_col2\"].describe()\n",
    "df.groupby(\"nombre_col1\")[\"nombre_col2\"].sum()\n",
    "df.groupby(\"nombre_col1\")[\"nombre_col2\"].mean()    \n",
    "\n",
    "\n",
    "#COMPLETAR CON MÉTODOS Aggregate, filter, transform, apply\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = pd.concat([df1, df2], ignore_index=True) \n",
    "\n",
    "#esto concatena dos df en vertical(pone el 2º debajo del 1º) y renumera el índice. Ojo que los df tienen que tener las \n",
    "#mismas dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusionar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generamos un nuevo dataframe fusionado por la columna 1, indicandole que queremos que aparezcan también las columnas 2 a 4.\n",
    "\n",
    "df_merged = pd.merge(df_1, df_2[[\"col2\",\"col3\",\"col4\"]], on = \"col1\",how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir un dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usamos groupby para hacerlo\n",
    "\n",
    "groups = df.groupby(df[\"Clase\"])\n",
    "\n",
    "primera_df = groups.get_group(\"primera\")\n",
    "segunda_df = groups.get_group(\"segunda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar el dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Máscaras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Las máscaras se aplican siempre entre corchetes\n",
    "\n",
    "df[\"Tipo\"].isin([\"Aumento\"])#creamos una máscara para filtrar las filas/registros  que contienen\n",
    "                            #el string \"Aumento\" en la columna \"Tipo\"\n",
    "                            #usamos el método isin() y los corchetes para contener las columnas y valores.\n",
    "                            #La máscara devuelve una Serie cuyos valores son booleanos.\n",
    "            \n",
    "df[df[\"Tipo\"].isin([\"Aumento\"])]#Así aplicamos la máscara al dataframe.\n",
    "\n",
    "#Aplicamos la máscara y seleccionamos con doble corchete las columnas que queremos que muestre el df resultante.\n",
    "df[df[\"Tipo\"].isin([\"Aumento\"])][[\"Partidas\", \"Tipo\", \"Todos\"]] \n",
    "    \n",
    "\n",
    "# Máscara que utiliza el metodo str.startswith. Recuerda que puedes utilizar estos métodos str sobre las columnas.\n",
    "df[\"Partidas\"].str.startswith(\"nombrevalor\")\n",
    "\n",
    "# Máscara que utiliza el metodo str.contains.\n",
    "    \n",
    "df[\"Partidas\"].str.contains(\"nombrevalor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Método Filter de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrado por columnas explícito:\n",
    "\n",
    "df.filter(items = [\"col1\",\"col2\"])#para Dataframes, items es igual a columns. Para Series es index.\n",
    "\n",
    "#filtrado de columnas cuyo nombre contenga el valor indicado, en este caso solo queremos la col1:\n",
    "\n",
    "df.filter(like='1', axis=1)\n",
    "\n",
    "#Filtrado por el valor explícito (etiqueta) del índice:\n",
    "\n",
    "df.filter(items = [\"index1\",\"index2\"], axis = 0)\n",
    "\n",
    "#filtrado de filas por el valor explícito (etiqueta) del índice en like, en este caso solo queremos las etiquetas de incluyan un 2.\n",
    "\n",
    "df.filter(like='2', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redondear decimales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si quieres redondear todos los numeros del DF haces:\n",
    "\n",
    "df = df.round(2)  # 2 decimales\n",
    "\n",
    "#si quieres solo de una columna concreta.\n",
    "\n",
    "df = df.round({\"nombre columna\":2}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otros métodos de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suprimir la notación científica\n",
    "\n",
    "#Solo para visualizar:\n",
    "\n",
    "#Números con cero decimales\n",
    "pd.set_option('display.float_format', '{:.0f}'.format)\n",
    "\n",
    "#Números con dos decimales\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "#Para utilizar los números\n",
    "\n",
    "df.astype(\"int\")\n",
    "df.astype(\"int64\")#si los números son muy grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para generar una nueva variable con el valor acumulado de otra\n",
    "\n",
    "df[\"acumulado\"]= = df[\"col\"].cumsum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para generar una nueva variable con el porcentaje de cada instancia sobre el total\n",
    "\n",
    " df['col %'] = (df[\"col\"] / df[\"col\"].sum())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para generar una nueva variable con el porcentaje de cada instancia sobre el total\n",
    "\n",
    " df['col %'] = (df[\"col\"] / df[\"col\"].sum())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformar un columna de fechas (strings) en un objeto datetime y extraer el mes y el trimestre\n",
    "\n",
    "\n",
    "df[\"date_column\"] = pd.to_datetime(df_operational[\"Date en strings\"])\n",
    "\n",
    "df['quarter'] = df['date_column'].dt.quarter\n",
    "df['Quarter_Info'] = df['date_column'].dt.to_period('Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ver varios dataframe a la vez\n",
    "\n",
    "from IPython.display import display \n",
    "\n",
    "display(df1,df2,df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Información util Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(elemento)#para ver el tipo de elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para generar variables con nombres similares, por ejemplo, numeradas, de forma automática. Se hace usando un bucle. \n",
    "\n",
    "# \"Existe la posibilidad de crear variables al vuelo de varias formas como editar los diccionarios que definen el namespace globals o locals, \n",
    "# usar exec()/eval() o setattr() si estamos usando clases.(https://es.stackoverflow.com/questions/60867/crear-objetos-con-nombres-similares-con-un-ciclo-for-en-python)\n",
    "\n",
    "for i in range(1,26):\n",
    "    globals()['variable{}'.format(i)] = i * 2\n",
    "#print(variable1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 grados son 0.08 radianes.\n",
      "38 grados son 0.08 radianes.\n",
      "one two\n",
      "two one\n",
      "Geeks and Portal\n"
     ]
    }
   ],
   "source": [
    "#Formas de imprimir en python con print\n",
    "grados = 38\n",
    "radianes = 0.08\n",
    "\n",
    "print(\"%s grados son %s radianes.\" % (grados, radianes))\n",
    "print(\"{} grados son {} radianes.\".format(grados, radianes))\n",
    "\n",
    "#Con la segunda manera se puede cambiar el orden de los argumentos\n",
    "print('{} {}'.format('one', 'two'))\n",
    "print('{1} {0}'.format('one', 'two'))\n",
    "\n",
    "print(f\"{'Geeks'} and {'Portal'}\")\n",
    "\n",
    "#El método format es muy útil: https://pyformat.info/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item.replace(\"\\n\",\" \").replace(\" ($)\", \"\") for item in lista] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir una lista en un diccionario usando enumerate y comprehension\n",
    "\n",
    "diccionario ={i:elem for i:elem in enumerate(lista)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear nueva columna con rangos o bins: pd.cut y pd.qcut\n",
    "#https://www.datasciencemadesimple.com/binning-or-bucketing-of-column-in-pandas-python-2/\n",
    "\n",
    "bins = [0, 25, 50, 75, 100]\n",
    "labels =[1,2,3,4]\n",
    "df['binned'] = pd.cut(df['col de la que quiero sacar rangos'], bins, labels= labels)    \n",
    "\n",
    "bin_labels=[0, 1, 2]\n",
    "df_clean['attractiveness'] = pd.cut(x=df_clean['venture'], bins=[-1,50000,2000000,40305028],labels=bin_labels)\n",
    "\n",
    "#Labels pueden ser strings, por ejemplo [\"Low ETR\", \"Medium ETR, \"High ETR\"]\n",
    "\n",
    "#Para que lo reparta de forma automática:\n",
    "\n",
    "pd.cut(df['col de la que quiero sacar rangos'], 5).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar dataframe en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"df.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo en un pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finished_model.model'\n",
    "\n",
    "with open(filename, 'wb') as archivo_salida:\n",
    "    pickle.dump(modelo, archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No me funciona, ver con Ander.\n",
    "\n",
    "import os\n",
    "\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"nombres\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "    \n",
    "save_fig(\"Nombre del archivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Esto sí funciona, una vez instalado kaleido.\n",
    "#pip install -U kaleido\n",
    "\n",
    "import kaleido\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.mkdir(\"images\")\n",
    "    \n",
    "#---\n",
    "\n",
    "fig.write_image(\"images/name.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cb57b3ccfe62c6746bf3247651268e5f45d4314d13d2f08503817b1c05971834"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
